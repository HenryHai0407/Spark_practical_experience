{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001B0F0046B30>\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark exercise 2\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([\n",
    "    (1,'2013-07-25 00:00:00',11599, 'CLOSED'),\n",
    "    (2,'2013-07-25 00:00:00',256, 'PENDING_PAYMENT'),\n",
    "    (3,'2013-07-25 00:00:00',12111, 'COMPLETE'),\n",
    "    (4,'2013-07-25 00:00:00',8827, 'CLOSED'),\n",
    "    (5,'2013-07-25 00:00:00',11318, 'COMPLETE'),\n",
    "    (6,'2013-07-25 00:00:00',7130, 'COMPLETE'),\n",
    "    (7,'2013-07-25 00:00:00',4530, 'COMPLETE'),\n",
    "    (8,'2013-07-25 00:00:00',2911, 'PROCESSING'),\n",
    "    (9,'2013-07-25 00:00:00',5657, 'PENDING_PAYMENT'),\n",
    "    (10,'2013-07-25 00:00:00',5648, 'PENDING_PAYMENT'),\n",
    "    (11,'2013-07-25 00:00:00',918, 'PAYMENT_REVIEW'),\n",
    "    (12,'2013-07-25 00:00:00',1837, 'CLOSED'),\n",
    "    (13,'2013-07-25 00:00:00',9149, 'PENDING_PAYMENT'),\n",
    "    (14,'2013-07-25 00:00:00',9842, 'PROCESSING'),\n",
    "    (15,'2013-07-25 00:00:00',2568, 'COMPLETE'),\n",
    "    (16,'2013-07-25 00:00:00',7276, 'PENDING_PAYMENT'),\n",
    "    (17,'2013-07-25 00:00:00',2667, 'COMPLETE'),\n",
    "    (18,'2013-07-25 00:00:00',1205, 'CLOSED'),\n",
    "    (19,'2013-07-25 00:00:00',9488, 'PENDING_PAYMENT'),\n",
    "    (20,'2013-07-25 00:00:00',9198, 'PROCESSING'),\n",
    "    # Please add more orders for existing customers\n",
    "    (21,'2013-07-25 00:00:00',11599, 'CLOSED'),\n",
    "    (22,'2013-07-25 00:00:00',256, 'PENDING_PAYMENT'),\n",
    "    (23,'2013-07-25 00:00:00',12111, 'COMPLETE'),\n",
    "    (24,'2013-07-25 00:00:00',8827, 'CLOSED'),\n",
    "    (25,'2013-07-25 00:00:00',11318, 'COMPLETE'),\n",
    "    (26,'2013-07-25 00:00:00',7130, 'COMPLETE'),\n",
    "    (27,'2013-07-25 00:00:00',4530, 'COMPLETE'),\n",
    "    (28,'2013-07-25 00:00:00',2911, 'PROCESSING'),\n",
    "    (29,'2013-07-25 00:00:00',5657, 'PENDING_PAYMENT'),\n",
    "    (30,'2013-07-25 00:00:00',5648, 'PENDING_PAYMENT'),\n",
    "    (31,'2013-07-25 00:00:00',918, 'PAYMENT_REVIEW'),\n",
    "    (32,'2013-07-25 00:00:00',1837, 'CLOSED'),\n",
    "    (33,'2013-07-25 00:00:00',9149, 'PENDING_PAYMENT'),\n",
    "    (34,'2013-07-25 00:00:00',9842, 'PROCESSING'),\n",
    "    (35,'2013-07-25 00:00:00',2568, 'COMPLETE'),\n",
    "    (36,'2013-07-25 00:00:00',7276, 'PENDING_PAYMENT'),\n",
    "    (37,'2013-07-25 00:00:00',2667, 'COMPLETE'),\n",
    "    (38,'2013-07-25 00:00:00',1205, 'CLOSED'),\n",
    "    (39,'2013-07-25 00:00:00',9488, 'PENDING_PAYMENT'),\n",
    "    (40,'2013-07-25 00:00:00',9198, 'PROCESSING'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the RDD to a DF\n",
    "from pyspark.sql import Row\n",
    "df = rdd.map(lambda x: Row(order_id=x[0], order_date=x[1], customer_id=x[2], status=x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "schema = types.StructType([\n",
    "    types.StructField('order_id', types.IntegerType(), True),\n",
    "    types.StructField('order_date', types.StringType(), True),\n",
    "    types.StructField('customer_id', types.IntegerType(), True),\n",
    "    types.StructField('status', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF with Schema\n",
    "df = spark.createDataFrame(df, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df = df.withColumn('order_date', F.to_timestamp(df['order_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check Schema  \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|         status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update order_date from timestamp to date\n",
    "df = df.withColumn('order_date', F.to_date(df['order_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|order_id|order_date|customer_id|         status|\n",
      "+--------+----------+-----------+---------------+\n",
      "|       1|2013-07-25|      11599|         CLOSED|\n",
      "|       2|2013-07-25|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|      12111|       COMPLETE|\n",
      "|       4|2013-07-25|       8827|         CLOSED|\n",
      "|       5|2013-07-25|      11318|       COMPLETE|\n",
      "+--------+----------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|         status|count|\n",
      "+---------------+-----+\n",
      "|PENDING_PAYMENT|   12|\n",
      "|       COMPLETE|   12|\n",
      "|         CLOSED|    8|\n",
      "|     PROCESSING|    6|\n",
      "| PAYMENT_REVIEW|    2|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1: The number of orders for each status\n",
    "df_1 = df.groupBy('status').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       8827|    2|\n",
      "|      12111|    2|\n",
      "|      11318|    2|\n",
      "|        256|    2|\n",
      "|      11599|    2|\n",
      "|       4530|    2|\n",
      "|       2911|    2|\n",
      "|       5657|    2|\n",
      "|       7130|    2|\n",
      "|       5648|    2|\n",
      "|        918|    2|\n",
      "|       9842|    2|\n",
      "|       1837|    2|\n",
      "|       2568|    2|\n",
      "|       9149|    2|\n",
      "|       9488|    2|\n",
      "|       2667|    2|\n",
      "|       1205|    2|\n",
      "|       9198|    2|\n",
      "|       7276|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2: Top 10 customers who have placed the most orders\n",
    "df_2 = df.groupBy('customer_id').count().orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: Total number of customers who have placed orders\n",
    "df_3 = df.select('customer_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: Total number of customers who have placed orders using SQL\n",
    "orders = df.createOrReplaceTempView('orders')\n",
    "df_33 = spark.sql('select count(distinct customer_id) as total_customers from orders')\n",
    "df_33.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
